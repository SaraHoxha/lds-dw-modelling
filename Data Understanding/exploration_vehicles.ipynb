{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Vehicles Table\n",
    "data = pd.read_csv('../data/Vehicles.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check info of vehicles table\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing and Unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check number of unique values for each column\n",
    "for col in data.columns:\n",
    "    print(str(col) +\": \"+ str(data[col].nunique()))\n",
    "\n",
    "\n",
    "print(\"------------------------\")\n",
    "#Check number of missing values for each column\n",
    "for col in data.columns:\n",
    "    print(str(col) +\": \"+ str(data[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum character length for string attributes of Vehicles csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check maximum character length for string attributes of vehicles\n",
    "for col in data.columns:\n",
    "    if data[f\"{col}\"].dtype == \"object\":\n",
    "        print(f\"{col}: \"+ str(data[f\"{col}\"].str.len().max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes to make in the attribute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"UNIT_NO:\"+str(data[\"UNIT_NO\"].unique())) #number of units implicated in the rd_no case(No change)\n",
    "print(\"---------------\")\n",
    "print(\"UNIT_TYPE:\"+str(data[\"UNIT_TYPE\"].unique())) #Change to UNKNOWN the nan's\n",
    "print(\"---------------\")\n",
    "print(\"LIC_PLATE_STATE:\"+str(data[\"LIC_PLATE_STATE\"].unique())) #lic plate state we should rename xx and nan as unknown\n",
    "print(\"---------------\")\n",
    "# According to the Chicago PD website, if MAKE and/or MODEL are NA, they are not considered relevant or important so can be left as is\n",
    "# MAKE column has some typos to fix\n",
    "# MODEL column has two different UNKNOWNS, which is probably a typo\n",
    "print(\"VEHICLE_YEAR:\"+str(data[\"VEHICLE_YEAR\"].unique())) #Change the vehicles year from 2024 up, to UNKNOWN, NA to UNKNOWN too\n",
    "print(\"---------------\")\n",
    "print(\"VEHICLE_DEFECT:\"+str(data[\"VEHICLE_DEFECT\"].unique())) #modify NAN to UNKNOWN\n",
    "print(\"---------------\")\n",
    "print(\"VEHICLE_TYPE:\"+str(data[\"VEHICLE_TYPE\"].unique())) #Change NAN to UNKNOWN/NA\n",
    "print(\"---------------\")\n",
    "print(\"VEHICLE_USE:\"+str(data[\"VEHICLE_USE\"].unique())) #Change NAN to UNKNOWN/NA\n",
    "print(\"---------------\")\n",
    "print(\"TRAVEL_DIRECTION:\"+str(data[\"TRAVEL_DIRECTION\"].unique())) #Change NAN to UNKNOWN\n",
    "print(\"---------------\")\n",
    "print(\"MANEUVER:\"+str(data[\"MANEUVER\"].unique())) #Change NAN to UNKNOWN\n",
    "print(\"---------------\")\n",
    "print(\"OCCUPANT_CNT:\"+str(data[\"OCCUPANT_CNT\"].unique())) #Numbers appear right\n",
    "print(\"---------------\")\n",
    "print(\"FIRST_CONTACT_POINT:\"+str(data[\"FIRST_CONTACT_POINT\"].unique())) #Change NAN to UNKNOWN\n",
    "print(\"---------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNIT_TYPE Analysis:\n",
    "While we could determine the vehicle type from MAKE and MODEL when UNIT_TYPE is NaN, this field also represents the vehicle's status during the crash (parked, driven, etc.). Therefore, we cannot accurately determine the UNIT_TYPE from other fields alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### License_Plate Analysis:\n",
    "The column contains both a placeholder value (XX) and NaN values. Since this is a string column, we should standardize by replacing both with 'UNKNOWN'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VEHICLE_YEAR Analysis:\n",
    "The column contains NaN values, some values greater than 2024 as well as a value (9999) that appears to be a typo for 1999. It has a lot of occurences (257). We could fix the typo by replacing it with 1999, and setting the years greater than 2024 as 'UNKNOWN'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = data[(data['VEHICLE_YEAR'] > 2024) & data['VEHICLE_YEAR'].notnull()]\n",
    "print(\"total entries with wrong year date: \" + str(len(filtered_df)))\n",
    "filtered_df = filtered_df[\"VEHICLE_YEAR\"].unique()\n",
    "print(\"unique entries with wrong year date: \" + str(filtered_df.size))\n",
    "#Count by vehicle year date\n",
    "\"\"\" for i in filtered_df:\n",
    "    print(str(i)+\": \"+str(data[data[\"VEHICLE_YEAR\"] == i][\"VEHICLE_YEAR\"].count()))\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VEHICLE_DEFECT Analysis:\n",
    "For vehicle defect we already have a label for UNKNOWN thus we can replace NAN's with this label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OCCUPANT_CNT Analysis:\n",
    "Very few vehicles are carrying more than 6 persons during the accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = data[(data['OCCUPANT_CNT'] > 6) & data['OCCUPANT_CNT'].notnull()]\n",
    "print(\"total entries with more than usual ppl: \" + str(len(filtered_df)))\n",
    "filtered_df = filtered_df[\"OCCUPANT_CNT\"].unique()\n",
    "print(\"unique entries with more than usual ppl: \" + str(filtered_df.size))\n",
    "\"\"\" for i in filtered_df:\n",
    "    print(str(i)+\": \"+str(data[data[\"OCCUPANT_CNT\"] == i][\"OCCUPANT_CNT\"].count())) \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for semantic inconsistencies on vehicle make and model\n",
    "There exist some typos on the names of makes and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = data.dropna(subset=['MAKE','MODEL'])\n",
    "import Levenshtein\n",
    "\n",
    "def find_similar_words(word_list, threshold=2):\n",
    "\n",
    "    similar_words = []\n",
    "    for i in range(len(word_list)):\n",
    "        for j in range(i + 1, len(word_list)):\n",
    "            distance = Levenshtein.distance(word_list[i], word_list[j])\n",
    "            if distance <= threshold:\n",
    "                similar_words.append((word_list[i], word_list[j]))\n",
    "\n",
    "    return similar_words\n",
    "\n",
    "word_list = df_cleaned[\"MAKE\"].unique()\n",
    "similar_pairs = find_similar_words(word_list)\n",
    "print(similar_pairs)\n",
    "\n",
    "more_tan5_model = df_cleaned[df_cleaned['MAKE'].str.len() > 8].drop_duplicates()\n",
    "word_list = more_tan5_model['MAKE'].unique()\n",
    "similar_pairs = find_similar_words(word_list)\n",
    "print(similar_pairs)\n",
    "\n",
    "#('NEW HOLLAND, DIV. OF SPERRY NEW HOLLAND', 'NEW HOLLAND, (DIV. OF SPERRY NEW HOLLAND)')\n",
    "#('AMC (LAWN & GARDEN TRACTORS BY AMERICAN MOTORS)', 'AMC (LAWN & GARDEN TRACTORS BY AMMERICAN MOTORS)')\n",
    "#('ROLLS ROYCE', 'ROLLS-ROYCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = df_cleaned[\"MODEL\"].unique()\n",
    "similar_pairs = find_similar_words(word_list)\n",
    "print(similar_pairs)\n",
    "more_tan5_model = df_cleaned[df_cleaned['MODEL'].str.len() > 9].drop_duplicates()\n",
    "word_list = more_tan5_model['MODEL'].unique()\n",
    "similar_pairs = find_similar_words(word_list)\n",
    "print(similar_pairs)\n",
    "\n",
    "#('UNKNOWN', 'UNKOWN')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for crash dates in the future \n",
    "There are no dates in the future in regards to the crash date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' column to datetime format\n",
    "data['CRASH_DATE'] = pd.to_datetime(data['CRASH_DATE'])\n",
    "\n",
    "# Filter rows where the date is after 01/01/2024 12:00 AM\n",
    "filtered_df = data[data['CRASH_DATE'] >= pd.to_datetime('2020-01-01 00:00:00')]['CRASH_DATE']\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing how the vehicle type and the unit type stack up\n",
    "#### Most of the accidents happened during the driving of the vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/Vehicles_Processed.csv',encoding='utf-8')\n",
    "# Create a count plot\n",
    "sns.countplot(x=\"UNIT_TYPE\", data=data)\n",
    "# Adjust the font size of tick labels\n",
    "plt.tick_params(axis='both', which='major', labelsize=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The main directions are the most prevalent in the data of the vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot\n",
    "sns.countplot(x=\"TRAVEL_DIRECTION\", data=data)\n",
    "# Adjust the font size of tick labels\n",
    "plt.tick_params(axis='both', which='major', labelsize=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total, roof and others appear to be the less reported first contact points, this can be expected from a crashed car, while the most common are the front parts of the vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot\n",
    "sns.countplot(x=\"FIRST_CONTACT_POINT\", data=data)\n",
    "# Adjust the font size of tick labels\n",
    "plt.tick_params(axis='both', which='major', labelsize=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes to make in the attribute values\n",
    "1. UNIT_TYPE -> change nan’s to UNKNOWN\n",
    "2. LIC_PLATE_STATE -> change both nan’s and XX to UNKNOWN\n",
    "3. MAKE ->  has duplicates with typos in their names fix and replace one of the names\n",
    "4. MODEL -> has two UNKNOWN and UKNOW fix the typos\n",
    "5. VEHICLE_YEAR -> years above 2024 rename to UNKNOWN, nan’s also to UNKNOWN (BUT the year 999 appears as a typo for 1999, what to do? there’s nothing on their website about it)\n",
    "6. VEHICLE_DEFECT -> nan’s to UNKNOWN\n",
    "7. VEHICLE_TYPE -> nan’s to UNKNOWN/NA\n",
    "8. VEHICLE_USE -> nan’s to UNKNOWN/NA\n",
    "9. VEHICLE_DIRECTION -> nan’s to UNKNOWN\n",
    "10. MANEUVER -> nan’s to UNKNOWN\n",
    "11. FIRST_CONTACT_POINT -> nan’s to UNKNOWN\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterDS-exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
